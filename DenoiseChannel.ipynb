{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenoiseChannel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13SACsM3bbtStJp0uJKVMZNig-tl9jzYW",
      "authorship_tag": "ABX9TyP+aKl841Q4HyG90yZi5bGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjayesh/DeGAN/blob/main/DenoiseChannel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec-D9q-YvK8n",
        "outputId": "4d5686b8-a692-48d2-be5e-25d9b5ea26ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CBDNet-pytorch'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 149 (delta 15), reused 44 (delta 13), pack-reused 99\u001b[K\n",
            "Receiving objects: 100% (149/149), 7.77 MiB | 14.33 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IDKiro/CBDNet-pytorch.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "b7Jqt0B10lXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df226817-675c-404b-bad7-a91ee243f212"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t dev\t\t    lib    mnt\t       root  sys\t\tusr\n",
            "boot\t etc\t\t    lib32  opt\t       run   tensorflow-1.15.2\tvar\n",
            "content  home\t\t    lib64  proc        sbin  tmp\n",
            "datalab  ImageDenoisingGAN  media  python-apt  srv   tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ..\n"
      ],
      "metadata": {
        "id": "_mYOAF140dTm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ImageDenoisingGAN/"
      ],
      "metadata": {
        "id": "Yee50XBE0fl-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/manumathewthomas/ImageDenoisingGAN.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oahyXIGJ0nxh",
        "outputId": "e90467b5-6b0e-42c0-b4bb-af781c3c7fe5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageDenoisingGAN'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Total 101 (delta 0), reused 0 (delta 0), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (101/101), 22.47 MiB | 43.16 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive"
      ],
      "metadata": {
        "id": "eK-XYGJlFoS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ImageDenoisingGAN/eval_mse.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uDf1zjw0un_",
        "outputId": "650a6b2e-7b36-4fe8-affe-523804a747a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "(122, 51, 2)\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/test.py:14: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/test.py:18: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/conv_helper.py:7: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/conv_helper.py:8: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:650: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/conv_helper.py:30: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1607, in _create_c_op\n",
            "    c_op = c_api.TF_FinishOperation(op_desc)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Depth of output (2) is not a multiple of the number of groups (8) for 'g_deconv2/g_deconv2_deconv/Conv2D' (op: 'Conv2D') with input shapes: [?,122,51,32], [3,3,4,2].\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"ImageDenoisingGAN/eval_mse.py\", line 41, in <module>\n",
            "    Y_pred = denoise(X)\n",
            "  File \"/content/ImageDenoisingGAN/test.py\", line 48, in denoise\n",
            "    output = test(image)\n",
            "  File \"/content/ImageDenoisingGAN/test.py\", line 21, in test\n",
            "    Gz = generator(gen_in)\n",
            "  File \"/content/ImageDenoisingGAN/model.py\", line 20, in generator\n",
            "    deconv2 = deconvolution_layer(deconv1, [BATCH_SIZE, 122, 51, 2], \"g_deconv2\")\n",
            "  File \"/content/ImageDenoisingGAN/conv_helper.py\", line 35, in deconvolution_layer\n",
            "    return resize_deconvolution_layer(input_tensor, new_shape, scope_name)\n",
            "  File \"/content/ImageDenoisingGAN/conv_helper.py\", line 31, in resize_deconvolution_layer\n",
            "    output, unused_weights = conv_layer(output, 3, new_shape[3]*2, new_shape[3], 1, scope_name+\"_deconv\")\n",
            "  File \"/content/ImageDenoisingGAN/conv_helper.py\", line 9, in conv_layer\n",
            "    output = tf.nn.conv2d(input_image, filter, strides=[1, stride, stride, 1], padding='SAME')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n",
            "    data_format=data_format, dilations=dilations, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
            "    attrs, op_def, compute_device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1770, in __init__\n",
            "    control_input_ops)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1610, in _create_c_op\n",
            "    raise ValueError(str(e))\n",
            "ValueError: Depth of output (2) is not a multiple of the number of groups (8) for 'g_deconv2/g_deconv2_deconv/Conv2D' (op: 'Conv2D') with input shapes: [?,122,51,32], [3,3,4,2].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFj0Qv0UGxqc",
        "outputId": "21e4d259-c22b-44e7-dd1e-81d3016a8560"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 21 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.14.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.44.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 10.1 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=b6db8b5d282de6af3d35c6474302566ce6e3879cd10d7c02abe8cec8ec993f44\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_data(db: int):\n",
        "  from numpy import genfromtxt\n",
        "  X_train = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/zls_train.csv', delimiter=',')\n",
        "  Y_train = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/z_train.csv', delimiter=',')\n",
        "\n",
        "  X_valid = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/zls_validate.csv', delimiter=',')\n",
        "  Y_valid = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/z_validate.csv', delimiter=',')\n",
        "\n",
        "  X_test = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/zls_test.csv', delimiter=',')\n",
        "  Y_test = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/z_test.csv', delimiter=',')\n",
        "\n",
        "  X_train = np.reshape(X_train, [8000, 10, 51, 2]);\n",
        "  Y_train = np.reshape(Y_train, [8000, 10, 51, 2]);\n",
        "\n",
        "  X_valid = np.reshape(X_valid, [4000, 10, 51, 2]);\n",
        "  Y_valid = np.reshape(Y_valid, [4000, 10, 51, 2]);\n",
        "\n",
        "  X_test = np.reshape(X_test, [3000, 10, 51, 2]);\n",
        "  Y_test = np.reshape(Y_test, [3000, 10, 51, 2]);\n",
        "\n",
        "  X_train = X_train.astype('float32') / 255;\n",
        "  Y_train = Y_train.astype('float32') / 255;\n",
        "  X_valid = X_valid.astype('float32') / 255;\n",
        "  Y_valid = Y_valid.astype('float32') / 255;\n",
        "  X_test = X_test.astype('float32') / 255;\n",
        "  Y_test = Y_test.astype('float32') / 255;\n",
        "\n",
        "  return X_train, Y_train, X_valid, Y_valid, X_test, Y_test\n",
        "\n",
        "\n",
        "def calculate_mse(Y_pred, Y_test):\n",
        "  return np.square(np.subtract(Y_pred, Y_test)).mean()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  X_train, Y_train, X_valid, Y_valid, X_test, Y_test = get_data(10)\n",
        "  mse = 0\n",
        "  for idx, X in enumerate(X):\n",
        "    Y_pred = denoise(X_test)\n",
        "    mse += calculate_mse(Y_pred, Y_test[idx])\n",
        "\n",
        "  print(\"Average MSE: \", mse/len(X_test))"
      ],
      "metadata": {
        "id": "Zrmdm5UeJf5I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import glob\n",
        "import scipy.misc\n",
        "from itertools import cycle\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from libs import vgg16\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "LEARNING_RATE = 0.002\n",
        "BATCH_SIZE = 1\n",
        "BATCH_SHAPE = [BATCH_SIZE, 122, 51, 2]\n",
        "SKIP_STEP = 10\n",
        "N_EPOCHS = 500\n",
        "CKPT_DIR = './Checkpoints/'\n",
        "IMG_DIR = './Images/'\n",
        "GRAPH_DIR = './Graphs/'\n",
        "TRAINING_SET_DIR= './dataset/training/'\n",
        "# GROUNDTRUTH_SET_DIR='./dataset/groundtruth/'\n",
        "VALIDATION_SET_DIR='./dataset/validation/'\n",
        "METRICS_SET_DIR='./dataset/metrics/'\n",
        "TRAINING_DIR_LIST = []\n",
        "ADVERSARIAL_LOSS_FACTOR = 0.5\n",
        "PIXEL_LOSS_FACTOR = 1.0\n",
        "STYLE_LOSS_FACTOR = 1.0\n",
        "SMOOTH_LOSS_FACTOR = 1.0\n",
        "# metrics_image = scipy.misc.imread(METRICS_SET_DIR+'gt.png', mode='RGB').astype('float32')\n",
        "\n",
        "\n",
        "def initialize(sess):\n",
        "    saver = tf.train.Saver()\n",
        "    writer = tf.summary.FileWriter(GRAPH_DIR, sess.graph)\n",
        "\n",
        "    if not os.path.exists(CKPT_DIR):\n",
        "        os.makedirs(CKPT_DIR)\n",
        "    if not os.path.exists(IMG_DIR):\n",
        "        os.makedirs(IMG_DIR)\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(CKPT_DIR))\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "    return saver\n",
        "\n",
        "def get_training_dir_list():\n",
        "    training_list = [d[1] for d in os.walk(TRAINING_SET_DIR)]\n",
        "    global TRAINING_DIR_LIST\n",
        "    TRAINING_DIR_LIST = training_list[0]\n",
        "    return TRAINING_DIR_LIST\n",
        "\n",
        "def load_next_training_batch():\n",
        "    batch = next(pool)\n",
        "\n",
        "    # filelist = sorted(glob.glob(TRAINING_SET_DIR+ batch +'/*.png'), key=alphanum_key)\n",
        "    # batch = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "    # npad =((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "    # batch = np.pad(batch, pad_width=npad, mode='constant', constant_values=0)\n",
        "    return batch\n",
        "\n",
        "# def load_groundtruth():\n",
        "#     filelist = sorted(glob.glob(GROUNDTRUTH_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "#     groundtruth = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "#     # npad = ((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "#     # groundtruth = np.pad(groundtruth, pad_width=npad, mode='constant', constant_values=0)\n",
        "#     return groundtruth\n",
        "\n",
        "def load_validation():\n",
        "    filelist = sorted(glob.glob(VALIDATION_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "    validation = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "    npad = ((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "    validation = np.pad(validation, pad_width=npad, mode='constant', constant_values=0)\n",
        "    return validation\n",
        "\n",
        "def training_dataset_init():\n",
        "    filelist = sorted(glob.glob(TRAINING_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "    batch = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "    batch = split(batch, BATCH_SIZE)\n",
        "    training_dir_list = get_training_dir_list()\n",
        "    global pool\n",
        "    pool = cycle(batch)\n",
        "    # return training_dir_list\n",
        "\n",
        "\n",
        "def imsave(filename, image):\n",
        "    scipy.misc.imsave(IMG_DIR+filename+'.png', image)\n",
        "\n",
        "def merge_images(file1, file2):\n",
        "    \"\"\"Merge two images into one, displayed side by side\n",
        "    :param file1: path to first image file\n",
        "    :param file2: path to second image file\n",
        "    :return: the merged Image object\n",
        "    \"\"\"\n",
        "    image1 = Image.fromarray(np.uint8(file1))\n",
        "    image2 = Image.fromarray(np.uint8(file2))\n",
        "\n",
        "    (width1, height1) = image1.size\n",
        "    (width2, height2) = image2.size\n",
        "\n",
        "    result_width = width1 + width2\n",
        "    result_height = max(height1, height2)\n",
        "\n",
        "    result = Image.new('RGB', (result_width, result_height))\n",
        "    result.paste(im=image1, box=(0, 0))\n",
        "    result.paste(im=image2, box=(width1, 0))\n",
        "    return result\n",
        "\n",
        "\n",
        "def tryint(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except:\n",
        "        return s\n",
        "\n",
        "def alphanum_key(s):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "\n",
        "def split(arr, size):\n",
        "    arrs = []\n",
        "    while len(arr) > size:\n",
        "        pice = arr[:size]\n",
        "        arrs.append(pice)\n",
        "        arr = arr[size:]\n",
        "    arrs.append(arr)\n",
        "    return arrs\n",
        "\n",
        "\n",
        "def lrelu(x, leak=0.2, name='lrelu'):\n",
        "    with tf.variable_scope(name):\n",
        "        f1 = 0.5 * (1 + leak)\n",
        "        f2 = 0.5 * (1 - leak)\n",
        "        return f1 * x + f2 * abs(x)\n",
        "\n",
        "def RGB_TO_BGR(img):\n",
        "    img_channel_swap = img[..., ::-1]\n",
        "    # img_channel_swap_1 = tf.reverse(img, axis=[-1])\n",
        "    return img_channel_swap\n",
        "\n",
        "\n",
        "def get_pixel_loss(target,prediction):\n",
        "    pixel_difference = target - prediction\n",
        "    pixel_loss = tf.nn.l2_loss(pixel_difference)\n",
        "    return pixel_loss\n",
        "\n",
        "def get_style_layer_vgg16(image):\n",
        "    net = vgg16.get_vgg_model()\n",
        "    style_layer = 'conv2_2/conv2_2:0'\n",
        "    feature_transformed_image = tf.import_graph_def(\n",
        "        net['graph_def'],\n",
        "        name='vgg',\n",
        "        input_map={'images:0': image},return_elements=[style_layer])\n",
        "    feature_transformed_image = (feature_transformed_image[0])\n",
        "    return feature_transformed_image\n",
        "\n",
        "def get_style_loss(target,prediction):\n",
        "    feature_transformed_target = get_style_layer_vgg16(target)\n",
        "    feature_transformed_prediction = get_style_layer_vgg16(prediction)\n",
        "    feature_count = tf.shape(feature_transformed_target)[3]\n",
        "    style_loss = tf.reduce_sum(tf.square(feature_transformed_target-feature_transformed_prediction))\n",
        "    style_loss = style_loss/tf.cast(feature_count, tf.float32)\n",
        "    return style_loss\n",
        "\n",
        "def get_smooth_loss(image):\n",
        "    batch_count = tf.shape(image)[0]\n",
        "    image_height = tf.shape(image)[1]\n",
        "    image_width = tf.shape(image)[2]\n",
        "\n",
        "    horizontal_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height, image_width-1,3])\n",
        "    horizontal_one_right = tf.slice(image, [0, 0, 1,0], [batch_count, image_height, image_width-1,3])\n",
        "    vertical_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height-1, image_width,3])\n",
        "    vertical_one_right = tf.slice(image, [0, 1, 0,0], [batch_count, image_height-1, image_width,3])\n",
        "    smooth_loss = tf.nn.l2_loss(horizontal_normal-horizontal_one_right)+tf.nn.l2_loss(vertical_normal-vertical_one_right)\n",
        "    return smooth_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "J9H0FyZmCvQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from utils import *\n",
        "from model import *\n",
        "\n",
        "from skimage import measure\n",
        "\n",
        "\n",
        "\n",
        "def test(image):\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
        "\n",
        "    gen_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='generated_image')\n",
        "    real_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='groundtruth_image')\n",
        "\n",
        "    Gz = generator(gen_in)\n",
        "\n",
        "\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "\n",
        "        saver = initialize(sess)\n",
        "        initial_step = global_step.eval()\n",
        "\n",
        "        start_time = time.time()\n",
        "        n_batches = 200\n",
        "        total_iteration = n_batches * N_EPOCHS\n",
        "\n",
        "        image = sess.run(tf.map_fn(lambda img: tf.image.per_image_standardization(img), image))\n",
        "        image = sess.run(Gz, feed_dict={gen_in: image})\n",
        "        image = np.resize(image[0][56:, :, :], [144, 256, 3])\n",
        "        # imsave('output', image)\n",
        "        return image\n",
        "\n",
        "def denoise(image):\n",
        "    # image = scipy.misc.imread(image, mode='RGB').astype('float32')\n",
        "    npad = ((56, 56), (0, 0), (0, 0))\n",
        "    image = np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    print(image[0].shape)\n",
        "    output = test(image)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    image = scipy.misc.imread(sys.argv[-1], mode='RGB').astype('float32')\n",
        "    npad = ((56, 56), (0, 0), (0, 0))\n",
        "    image = np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    print(image[0].shape)\n",
        "    test(image)\n"
      ],
      "metadata": {
        "id": "CohQXoL4Cxs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "\n",
        "from utils import *\n",
        "from conv_helper import *\n",
        "\n",
        "\n",
        "def generator(input):\n",
        "    conv1, conv1_weights = conv_layer(input, 9, 2, 32, 1, \"g_conv1\")\n",
        "    conv2, conv2_weights = conv_layer(conv1, 3, 32, 64, 1, \"g_conv2\")\n",
        "    # conv3, conv3_weights = conv_layer(conv2, 3, 64, 128, 1, \"g_conv3\")\n",
        "\n",
        "    res1, res1_weights = residual_layer(conv3, 3, 64, 64, 1, \"g_res1\")\n",
        "    res2, res2_weights = residual_layer(res1, 3, 64, 64, 1, \"g_res2\")\n",
        "    res3, res3_weights = residual_layer(res2, 3, 64, 64, 1, \"g_res3\")\n",
        "\n",
        "    deconv1 = deconvolution_layer(res3, [BATCH_SIZE, 64, 64, 32], 'g_deconv1')\n",
        "    deconv2 = deconvolution_layer(deconv1, [BATCH_SIZE, 122, 51, 2], \"g_deconv2\")\n",
        "\n",
        "    deconv2 = deconv2 + conv1\n",
        "\n",
        "    conv4, conv4_weights = conv_layer(deconv2, 9, 2, 3, 1, \"g_conv5\", activation_function=tf.nn.tanh)\n",
        "\n",
        "    conv4 = conv4 + input\n",
        "    output = output_between_zero_and_one(conv4)\n",
        "\n",
        "    return output\n",
        "\n",
        "def discriminator(input, reuse=False):\n",
        "    conv1, conv1_weights = conv_layer(input, 4, 3, 48, 2, \"d_conv1\", reuse=reuse)\n",
        "    conv2, conv2_weights = conv_layer(conv1, 4, 48, 96, 2, \"d_conv2\", reuse=reuse)\n",
        "    conv3, conv3_weights = conv_layer(conv2, 4, 96, 192, 2, \"d_conv3\", reuse=reuse)\n",
        "    conv4, conv4_weights = conv_layer(conv3, 4, 192, 384, 1, \"d_conv4\", reuse=reuse)\n",
        "    conv5, conv5_weights = conv_layer(conv4, 4, 384, 1, 1, \"d_conv5\", activation_function=tf.nn.sigmoid, reuse=reuse)\n",
        "\n",
        "    return conv5\n"
      ],
      "metadata": {
        "id": "2wvvd_juFxMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}