{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenoiseChannel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13SACsM3bbtStJp0uJKVMZNig-tl9jzYW",
      "authorship_tag": "ABX9TyPYxA8QebIdnbI/YF1y5Fl8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjayesh/DeGAN/blob/main/DenoiseChannel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec-D9q-YvK8n",
        "outputId": "4d5686b8-a692-48d2-be5e-25d9b5ea26ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CBDNet-pytorch'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 149 (delta 15), reused 44 (delta 13), pack-reused 99\u001b[K\n",
            "Receiving objects: 100% (149/149), 7.77 MiB | 14.33 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IDKiro/CBDNet-pytorch.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "b7Jqt0B10lXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df226817-675c-404b-bad7-a91ee243f212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t dev\t\t    lib    mnt\t       root  sys\t\tusr\n",
            "boot\t etc\t\t    lib32  opt\t       run   tensorflow-1.15.2\tvar\n",
            "content  home\t\t    lib64  proc        sbin  tmp\n",
            "datalab  ImageDenoisingGAN  media  python-apt  srv   tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ..\n"
      ],
      "metadata": {
        "id": "_mYOAF140dTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ImageDenoisingGAN/"
      ],
      "metadata": {
        "id": "Yee50XBE0fl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/manumathewthomas/ImageDenoisingGAN.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oahyXIGJ0nxh",
        "outputId": "e78e90b7-1e9f-42c5-817b-338ea34ee045"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageDenoisingGAN'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Total 101 (delta 0), reused 0 (delta 0), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (101/101), 22.47 MiB | 22.91 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive"
      ],
      "metadata": {
        "id": "eK-XYGJlFoS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ImageDenoisingGAN/eval_mse.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uDf1zjw0un_",
        "outputId": "40dcd768-ef2b-4517-b5a9-6673416133c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "(122, 51, 2)\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/test.py:14: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/test.py:18: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/conv_helper.py:7: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/conv_helper.py:8: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:650: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/conv_helper.py:30: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/test.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/test.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-04-22 13:33:09.878644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-22 13:33:09.892563: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-04-22 13:33:09.892615: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (29769abbba8a): /proc/driver/nvidia/version does not exist\n",
            "2022-04-22 13:33:09.892956: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-04-22 13:33:09.897724: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-04-22 13:33:09.897975: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558d1b9619c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-22 13:33:09.898016: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/utils.py:38: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ImageDenoisingGAN/utils.py:39: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Traceback (most recent call last):\n",
            "  File \"ImageDenoisingGAN/eval_mse.py\", line 43, in <module>\n",
            "    mse += calculate_mse(Y_pred, Y_test[idx])\n",
            "  File \"ImageDenoisingGAN/eval_mse.py\", line 35, in calculate_mse\n",
            "    Y_pred = np.reshape(Y_pred, [10, 51, 2])\n",
            "  File \"<__array_function__ internals>\", line 6, in reshape\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 298, in reshape\n",
            "    return _wrapfunc(a, 'reshape', newshape, order=order)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc\n",
            "    return bound(*args, **kwds)\n",
            "ValueError: cannot reshape array of size 110592 into shape (10,51,2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFj0Qv0UGxqc",
        "outputId": "efdb2621-0f29-49ff-8fcb-b1440f054af8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.44.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 24.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.14.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=16ed862dbfc9827f405ac732051716e2e4cc942fcb3cfc9f964c91b210a1cf68\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from test import *\n",
        "\n",
        "def get_data(db: int):\n",
        "  from numpy import genfromtxt\n",
        "  X_train = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/zls_train.csv', delimiter=',')\n",
        "  Y_train = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/z_train.csv', delimiter=',')\n",
        "\n",
        "  X_valid = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/zls_validate.csv', delimiter=',')\n",
        "  Y_valid = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/z_validate.csv', delimiter=',')\n",
        "\n",
        "  X_test = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/zls_test.csv', delimiter=',')\n",
        "  Y_test = genfromtxt(f'/content/drive/MyDrive/btp/data/btp{db}dbnew/z_test.csv', delimiter=',')\n",
        "\n",
        "  X_train = np.reshape(X_train, [8000, 10, 51, 2]);\n",
        "  Y_train = np.reshape(Y_train, [8000, 10, 51, 2]);\n",
        "\n",
        "  X_valid = np.reshape(X_valid, [4000, 10, 51, 2]);\n",
        "  Y_valid = np.reshape(Y_valid, [4000, 10, 51, 2]);\n",
        "\n",
        "  X_test = np.reshape(X_test, [3000, 10, 51, 2]);\n",
        "  Y_test = np.reshape(Y_test, [3000, 10, 51, 2]);\n",
        "\n",
        "  X_train = X_train.astype('float32') / 255;\n",
        "  Y_train = Y_train.astype('float32') / 255;\n",
        "  X_valid = X_valid.astype('float32') / 255;\n",
        "  Y_valid = Y_valid.astype('float32') / 255;\n",
        "  X_test = X_test.astype('float32') / 255;\n",
        "  Y_test = Y_test.astype('float32') / 255;\n",
        "\n",
        "  return X_train, Y_train, X_valid, Y_valid, X_test, Y_test\n",
        "\n",
        "\n",
        "def calculate_mse(Y_pred, Y_test):\n",
        "  Y_pred = np.reshape(Y_pred, [10, 51, 2])\n",
        "  return np.square(np.subtract(Y_pred, Y_test)).mean()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  X_train, Y_train, X_valid, Y_valid, X_test, Y_test = get_data(10)\n",
        "  mse = 0\n",
        "  for idx, X in enumerate(X_test):\n",
        "    Y_pred = denoise(X)\n",
        "    mse += calculate_mse(Y_pred, Y_test[idx])\n",
        "\n",
        "  print(\"Average MSE: \", mse/len(X_test))"
      ],
      "metadata": {
        "id": "Zrmdm5UeJf5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import glob\n",
        "import scipy.misc\n",
        "from itertools import cycle\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from libs import vgg16\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "LEARNING_RATE = 0.002\n",
        "BATCH_SIZE = 1\n",
        "BATCH_SHAPE = [BATCH_SIZE, 122, 51, 2]\n",
        "SKIP_STEP = 10\n",
        "N_EPOCHS = 500\n",
        "CKPT_DIR = './Checkpoints/'\n",
        "IMG_DIR = './Images/'\n",
        "GRAPH_DIR = './Graphs/'\n",
        "TRAINING_SET_DIR= './dataset/training/'\n",
        "# GROUNDTRUTH_SET_DIR='./dataset/groundtruth/'\n",
        "VALIDATION_SET_DIR='./dataset/validation/'\n",
        "METRICS_SET_DIR='./dataset/metrics/'\n",
        "TRAINING_DIR_LIST = []\n",
        "ADVERSARIAL_LOSS_FACTOR = 0.5\n",
        "PIXEL_LOSS_FACTOR = 1.0\n",
        "STYLE_LOSS_FACTOR = 1.0\n",
        "SMOOTH_LOSS_FACTOR = 1.0\n",
        "# metrics_image = scipy.misc.imread(METRICS_SET_DIR+'gt.png', mode='RGB').astype('float32')\n",
        "\n",
        "\n",
        "def initialize(sess):\n",
        "    saver = tf.train.Saver()\n",
        "    writer = tf.summary.FileWriter(GRAPH_DIR, sess.graph)\n",
        "\n",
        "    if not os.path.exists(CKPT_DIR):\n",
        "        os.makedirs(CKPT_DIR)\n",
        "    if not os.path.exists(IMG_DIR):\n",
        "        os.makedirs(IMG_DIR)\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(CKPT_DIR))\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "    return saver\n",
        "\n",
        "def get_training_dir_list():\n",
        "    training_list = [d[1] for d in os.walk(TRAINING_SET_DIR)]\n",
        "    global TRAINING_DIR_LIST\n",
        "    TRAINING_DIR_LIST = training_list[0]\n",
        "    return TRAINING_DIR_LIST\n",
        "\n",
        "def load_next_training_batch():\n",
        "    batch = next(pool)\n",
        "\n",
        "    # filelist = sorted(glob.glob(TRAINING_SET_DIR+ batch +'/*.png'), key=alphanum_key)\n",
        "    # batch = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "    # npad =((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "    # batch = np.pad(batch, pad_width=npad, mode='constant', constant_values=0)\n",
        "    return batch\n",
        "\n",
        "# def load_groundtruth():\n",
        "#     filelist = sorted(glob.glob(GROUNDTRUTH_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "#     groundtruth = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "#     # npad = ((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "#     # groundtruth = np.pad(groundtruth, pad_width=npad, mode='constant', constant_values=0)\n",
        "#     return groundtruth\n",
        "\n",
        "def load_validation():\n",
        "    filelist = sorted(glob.glob(VALIDATION_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "    validation = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "    npad = ((0, 0), (56, 56), (0, 0), (0, 0))\n",
        "    validation = np.pad(validation, pad_width=npad, mode='constant', constant_values=0)\n",
        "    return validation\n",
        "\n",
        "def training_dataset_init():\n",
        "    filelist = sorted(glob.glob(TRAINING_SET_DIR + '/*.png'), key=alphanum_key)\n",
        "    batch = np.array([np.array(scipy.misc.imread(fname, mode='RGB').astype('float32')) for fname in filelist])\n",
        "    batch = split(batch, BATCH_SIZE)\n",
        "    training_dir_list = get_training_dir_list()\n",
        "    global pool\n",
        "    pool = cycle(batch)\n",
        "    # return training_dir_list\n",
        "\n",
        "\n",
        "def imsave(filename, image):\n",
        "    scipy.misc.imsave(IMG_DIR+filename+'.png', image)\n",
        "\n",
        "def merge_images(file1, file2):\n",
        "    \"\"\"Merge two images into one, displayed side by side\n",
        "    :param file1: path to first image file\n",
        "    :param file2: path to second image file\n",
        "    :return: the merged Image object\n",
        "    \"\"\"\n",
        "    image1 = Image.fromarray(np.uint8(file1))\n",
        "    image2 = Image.fromarray(np.uint8(file2))\n",
        "\n",
        "    (width1, height1) = image1.size\n",
        "    (width2, height2) = image2.size\n",
        "\n",
        "    result_width = width1 + width2\n",
        "    result_height = max(height1, height2)\n",
        "\n",
        "    result = Image.new('RGB', (result_width, result_height))\n",
        "    result.paste(im=image1, box=(0, 0))\n",
        "    result.paste(im=image2, box=(width1, 0))\n",
        "    return result\n",
        "\n",
        "\n",
        "def tryint(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except:\n",
        "        return s\n",
        "\n",
        "def alphanum_key(s):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "\n",
        "def split(arr, size):\n",
        "    arrs = []\n",
        "    while len(arr) > size:\n",
        "        pice = arr[:size]\n",
        "        arrs.append(pice)\n",
        "        arr = arr[size:]\n",
        "    arrs.append(arr)\n",
        "    return arrs\n",
        "\n",
        "\n",
        "def lrelu(x, leak=0.2, name='lrelu'):\n",
        "    with tf.variable_scope(name):\n",
        "        f1 = 0.5 * (1 + leak)\n",
        "        f2 = 0.5 * (1 - leak)\n",
        "        return f1 * x + f2 * abs(x)\n",
        "\n",
        "def RGB_TO_BGR(img):\n",
        "    img_channel_swap = img[..., ::-1]\n",
        "    # img_channel_swap_1 = tf.reverse(img, axis=[-1])\n",
        "    return img_channel_swap\n",
        "\n",
        "\n",
        "def get_pixel_loss(target,prediction):\n",
        "    pixel_difference = target - prediction\n",
        "    pixel_loss = tf.nn.l2_loss(pixel_difference)\n",
        "    return pixel_loss\n",
        "\n",
        "def get_style_layer_vgg16(image):\n",
        "    net = vgg16.get_vgg_model()\n",
        "    style_layer = 'conv2_2/conv2_2:0'\n",
        "    feature_transformed_image = tf.import_graph_def(\n",
        "        net['graph_def'],\n",
        "        name='vgg',\n",
        "        input_map={'images:0': image},return_elements=[style_layer])\n",
        "    feature_transformed_image = (feature_transformed_image[0])\n",
        "    return feature_transformed_image\n",
        "\n",
        "def get_style_loss(target,prediction):\n",
        "    feature_transformed_target = get_style_layer_vgg16(target)\n",
        "    feature_transformed_prediction = get_style_layer_vgg16(prediction)\n",
        "    feature_count = tf.shape(feature_transformed_target)[3]\n",
        "    style_loss = tf.reduce_sum(tf.square(feature_transformed_target-feature_transformed_prediction))\n",
        "    style_loss = style_loss/tf.cast(feature_count, tf.float32)\n",
        "    return style_loss\n",
        "\n",
        "def get_smooth_loss(image):\n",
        "    batch_count = tf.shape(image)[0]\n",
        "    image_height = tf.shape(image)[1]\n",
        "    image_width = tf.shape(image)[2]\n",
        "\n",
        "    horizontal_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height, image_width-1,3])\n",
        "    horizontal_one_right = tf.slice(image, [0, 0, 1,0], [batch_count, image_height, image_width-1,3])\n",
        "    vertical_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height-1, image_width,3])\n",
        "    vertical_one_right = tf.slice(image, [0, 1, 0,0], [batch_count, image_height-1, image_width,3])\n",
        "    smooth_loss = tf.nn.l2_loss(horizontal_normal-horizontal_one_right)+tf.nn.l2_loss(vertical_normal-vertical_one_right)\n",
        "    return smooth_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "J9H0FyZmCvQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from utils import *\n",
        "from model import *\n",
        "\n",
        "from skimage import measure\n",
        "\n",
        "\n",
        "\n",
        "def test(image):\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
        "\n",
        "    gen_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='generated_image')\n",
        "    real_in = tf.placeholder(shape=[None, BATCH_SHAPE[1], BATCH_SHAPE[2], BATCH_SHAPE[3]], dtype=tf.float32, name='groundtruth_image')\n",
        "\n",
        "    Gz = generator(gen_in)\n",
        "\n",
        "\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "\n",
        "        saver = initialize(sess)\n",
        "        initial_step = global_step.eval()\n",
        "\n",
        "        start_time = time.time()\n",
        "        n_batches = 200\n",
        "        total_iteration = n_batches * N_EPOCHS\n",
        "\n",
        "        image = sess.run(tf.map_fn(lambda img: tf.image.per_image_standardization(img), image))\n",
        "        image = sess.run(Gz, feed_dict={gen_in: image})\n",
        "        image = np.resize(image[0][56:, :, :], [144, 256, 3])\n",
        "        # imsave('output', image)\n",
        "        return image\n",
        "\n",
        "def denoise(image):\n",
        "    # image = scipy.misc.imread(image, mode='RGB').astype('float32')\n",
        "    npad = ((56, 56), (0, 0), (0, 0))\n",
        "    image = np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    print(image[0].shape)\n",
        "    output = test(image)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    image = scipy.misc.imread(sys.argv[-1], mode='RGB').astype('float32')\n",
        "    npad = ((56, 56), (0, 0), (0, 0))\n",
        "    image = np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    print(image[0].shape)\n",
        "    test(image)\n"
      ],
      "metadata": {
        "id": "CohQXoL4Cxs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "\n",
        "from utils import *\n",
        "from conv_helper import *\n",
        "\n",
        "\n",
        "def generator(input):\n",
        "    conv1, conv1_weights = conv_layer(input, 9, 2, 32, 1, \"g_conv1\")\n",
        "    conv2, conv2_weights = conv_layer(conv1, 3, 32, 61, 1, \"g_conv2\")\n",
        "    # conv3, conv3_weights = conv_layer(conv2, 3, 64, 128, 1, \"g_conv3\")\n",
        "\n",
        "    res1, res1_weights = residual_layer(conv2, 3, 61, 61, 1, \"g_res1\")\n",
        "    res2, res2_weights = residual_layer(res1, 3, 61, 61, 1, \"g_res2\")\n",
        "    res3, res3_weights = residual_layer(res2, 3, 61, 61, 1, \"g_res3\")\n",
        "\n",
        "    deconv1 = deconvolution_layer(res3, [BATCH_SIZE, 61, 61, 61], 'g_deconv1')\n",
        "    deconv2 = deconvolution_layer(deconv1, [BATCH_SIZE, 122, 51, 32], \"g_deconv2\")\n",
        "\n",
        "    deconv2 = deconv2 + conv1\n",
        "\n",
        "    conv4, conv4_weights = conv_layer(deconv2, 9, 32, 2, 1, \"g_conv5\", activation_function=tf.nn.tanh)\n",
        "\n",
        "    conv4 = conv4 + input\n",
        "    # output = output_between_zero_and_one(conv4)\n",
        "\n",
        "    return conv4\n",
        "\n",
        "def discriminator(input, reuse=False):\n",
        "    conv1, conv1_weights = conv_layer(input, 4, 3, 48, 2, \"d_conv1\", reuse=reuse)\n",
        "    conv2, conv2_weights = conv_layer(conv1, 4, 48, 96, 2, \"d_conv2\", reuse=reuse)\n",
        "    conv3, conv3_weights = conv_layer(conv2, 4, 96, 192, 2, \"d_conv3\", reuse=reuse)\n",
        "    conv4, conv4_weights = conv_layer(conv3, 4, 192, 384, 1, \"d_conv4\", reuse=reuse)\n",
        "    conv5, conv5_weights = conv_layer(conv4, 4, 384, 1, 1, \"d_conv5\", activation_function=tf.nn.sigmoid, reuse=reuse)\n",
        "\n",
        "    return conv5\n"
      ],
      "metadata": {
        "id": "2wvvd_juFxMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "from utils import *\n",
        "\n",
        "def conv_layer(input_image, ksize, in_channels, out_channels, stride, scope_name, activation_function=lrelu, reuse=False):\n",
        "    with tf.variable_scope(scope_name):\n",
        "        filter = tf.Variable(tf.random_normal([ksize, ksize, in_channels, out_channels], stddev=0.03))\n",
        "        output = tf.nn.conv2d(input_image, filter, strides=[1, stride, stride, 1], padding='SAME')\n",
        "        output = slim.batch_norm(output)\n",
        "        if activation_function:\n",
        "            output = activation_function(output)\n",
        "        return output, filter\n",
        "\n",
        "def residual_layer(input_image, ksize, in_channels, out_channels, stride, scope_name):\n",
        "    with tf.variable_scope(scope_name):\n",
        "        output, filter = conv_layer(input_image, ksize, in_channels, out_channels, stride, scope_name+\"_conv1\")\n",
        "        output, filter = conv_layer(output, ksize, out_channels, out_channels, stride, scope_name+\"_conv2\")\n",
        "        output = tf.add(output, tf.identity(input_image))\n",
        "        return output, filter\n",
        "\n",
        "def transpose_deconvolution_layer(input_tensor, used_weights, new_shape, stride, scope_name):\n",
        "    with tf.varaible_scope(scope_name):\n",
        "        output = tf.nn.conv2d_transpose(input_tensor, used_weights, output_shape=new_shape, strides=[1, stride, stride, 1], padding='SAME')\n",
        "        output = tf.nn.relu(output)\n",
        "        return output\n",
        "\n",
        "def resize_deconvolution_layer(input_tensor, new_shape, scope_name):\n",
        "    with tf.variable_scope(scope_name):\n",
        "        output = tf.image.resize_images(input_tensor, (new_shape[1], new_shape[2]), method=1)\n",
        "        output, unused_weights = conv_layer(output, 3, 61, new_shape[3], 1, scope_name+\"_deconv\")\n",
        "        return output\n",
        "\n",
        "def deconvolution_layer(input_tensor, new_shape, scope_name):\n",
        "    return resize_deconvolution_layer(input_tensor, new_shape, scope_name)\n",
        "\n",
        "def output_between_zero_and_one(output):\n",
        "    output +=1\n",
        "    return output/2\n"
      ],
      "metadata": {
        "id": "9pZjZvFMf618"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}